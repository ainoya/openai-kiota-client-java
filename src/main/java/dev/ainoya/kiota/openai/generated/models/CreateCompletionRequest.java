package dev.ainoya.kiota.openai.generated.models;

import com.microsoft.kiota.serialization.AdditionalDataHolder;
import com.microsoft.kiota.serialization.ComposedTypeWrapper;
import com.microsoft.kiota.serialization.Parsable;
import com.microsoft.kiota.serialization.ParseNode;
import com.microsoft.kiota.serialization.SerializationWriter;
import java.util.HashMap;
import java.util.Map;
import java.util.Objects;
@jakarta.annotation.Generated("com.microsoft.kiota")
public class CreateCompletionRequest implements AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    private Map<String, Object> additionalData;
    /**
     * Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return  `best_of` must be greater than `n`.**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
     */
    private Integer bestOf;
    /**
     * Echo back the prompt in addition to the completion
     */
    private Boolean echo;
    /**
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
     */
    private Double frequencyPenalty;
    /**
     * Modify the likelihood of specified tokens appearing in the completion.Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
     */
    private CreateCompletionRequestLogitBias logitBias;
    /**
     * Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.The maximum value for `logprobs` is 5.
     */
    private Integer logprobs;
    /**
     * The maximum number of [tokens](/tokenizer) that can be generated in the completion.The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
     */
    private Integer maxTokens;
    /**
     * ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
     */
    private CreateCompletionRequestModel model;
    /**
     * How many completions to generate for each prompt.**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
     */
    private Integer n;
    /**
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
     */
    private Double presencePenalty;
    /**
     * The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
     */
    private CreateCompletionRequestPrompt prompt;
    /**
     * If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
     */
    private Integer seed;
    /**
     * Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
     */
    private CreateCompletionRequestStop stop;
    /**
     * Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
     */
    private Boolean stream;
    /**
     * The suffix that comes after a completion of inserted text.
     */
    private String suffix;
    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.We generally recommend altering this or `top_p` but not both.
     */
    private Double temperature;
    /**
     * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.We generally recommend altering this or `temperature` but not both.
     */
    private Double topP;
    /**
     * A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     */
    private String user;
    /**
     * Instantiates a new CreateCompletionRequest and sets the default values.
     */
    public CreateCompletionRequest() {
        this.setAdditionalData(new HashMap<>());
    }
    /**
     * Creates a new instance of the appropriate class based on discriminator value
     * @param parseNode The parse node to use to read the discriminator value and create the object
     * @return a CreateCompletionRequest
     */
    @jakarta.annotation.Nonnull
    public static CreateCompletionRequest createFromDiscriminatorValue(@jakarta.annotation.Nonnull final ParseNode parseNode) {
        Objects.requireNonNull(parseNode);
        return new CreateCompletionRequest();
    }
    /**
     * Gets the AdditionalData property value. Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     * @return a Map<String, Object>
     */
    @jakarta.annotation.Nonnull
    public Map<String, Object> getAdditionalData() {
        return this.additionalData;
    }
    /**
     * Gets the best_of property value. Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return  `best_of` must be greater than `n`.**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
     * @return a Integer
     */
    @jakarta.annotation.Nullable
    public Integer getBestOf() {
        return this.bestOf;
    }
    /**
     * Gets the echo property value. Echo back the prompt in addition to the completion
     * @return a Boolean
     */
    @jakarta.annotation.Nullable
    public Boolean getEcho() {
        return this.echo;
    }
    /**
     * The deserialization information for the current model
     * @return a Map<String, java.util.function.Consumer<ParseNode>>
     */
    @jakarta.annotation.Nonnull
    public Map<String, java.util.function.Consumer<ParseNode>> getFieldDeserializers() {
        final HashMap<String, java.util.function.Consumer<ParseNode>> deserializerMap = new HashMap<String, java.util.function.Consumer<ParseNode>>(17);
        deserializerMap.put("best_of", (n) -> { this.setBestOf(n.getIntegerValue()); });
        deserializerMap.put("echo", (n) -> { this.setEcho(n.getBooleanValue()); });
        deserializerMap.put("frequency_penalty", (n) -> { this.setFrequencyPenalty(n.getDoubleValue()); });
        deserializerMap.put("logit_bias", (n) -> { this.setLogitBias(n.getObjectValue(CreateCompletionRequestLogitBias::createFromDiscriminatorValue)); });
        deserializerMap.put("logprobs", (n) -> { this.setLogprobs(n.getIntegerValue()); });
        deserializerMap.put("max_tokens", (n) -> { this.setMaxTokens(n.getIntegerValue()); });
        deserializerMap.put("model", (n) -> { this.setModel(n.getObjectValue(CreateCompletionRequestModel::createFromDiscriminatorValue)); });
        deserializerMap.put("n", (n) -> { this.setN(n.getIntegerValue()); });
        deserializerMap.put("presence_penalty", (n) -> { this.setPresencePenalty(n.getDoubleValue()); });
        deserializerMap.put("prompt", (n) -> { this.setPrompt(n.getObjectValue(CreateCompletionRequestPrompt::createFromDiscriminatorValue)); });
        deserializerMap.put("seed", (n) -> { this.setSeed(n.getIntegerValue()); });
        deserializerMap.put("stop", (n) -> { this.setStop(n.getObjectValue(CreateCompletionRequestStop::createFromDiscriminatorValue)); });
        deserializerMap.put("stream", (n) -> { this.setStream(n.getBooleanValue()); });
        deserializerMap.put("suffix", (n) -> { this.setSuffix(n.getStringValue()); });
        deserializerMap.put("temperature", (n) -> { this.setTemperature(n.getDoubleValue()); });
        deserializerMap.put("top_p", (n) -> { this.setTopP(n.getDoubleValue()); });
        deserializerMap.put("user", (n) -> { this.setUser(n.getStringValue()); });
        return deserializerMap;
    }
    /**
     * Gets the frequency_penalty property value. Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
     * @return a Double
     */
    @jakarta.annotation.Nullable
    public Double getFrequencyPenalty() {
        return this.frequencyPenalty;
    }
    /**
     * Gets the logit_bias property value. Modify the likelihood of specified tokens appearing in the completion.Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
     * @return a CreateCompletionRequestLogitBias
     */
    @jakarta.annotation.Nullable
    public CreateCompletionRequestLogitBias getLogitBias() {
        return this.logitBias;
    }
    /**
     * Gets the logprobs property value. Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.The maximum value for `logprobs` is 5.
     * @return a Integer
     */
    @jakarta.annotation.Nullable
    public Integer getLogprobs() {
        return this.logprobs;
    }
    /**
     * Gets the max_tokens property value. The maximum number of [tokens](/tokenizer) that can be generated in the completion.The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
     * @return a Integer
     */
    @jakarta.annotation.Nullable
    public Integer getMaxTokens() {
        return this.maxTokens;
    }
    /**
     * Gets the model property value. ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
     * @return a CreateCompletionRequestModel
     */
    @jakarta.annotation.Nullable
    public CreateCompletionRequestModel getModel() {
        return this.model;
    }
    /**
     * Gets the n property value. How many completions to generate for each prompt.**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
     * @return a Integer
     */
    @jakarta.annotation.Nullable
    public Integer getN() {
        return this.n;
    }
    /**
     * Gets the presence_penalty property value. Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
     * @return a Double
     */
    @jakarta.annotation.Nullable
    public Double getPresencePenalty() {
        return this.presencePenalty;
    }
    /**
     * Gets the prompt property value. The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
     * @return a CreateCompletionRequestPrompt
     */
    @jakarta.annotation.Nullable
    public CreateCompletionRequestPrompt getPrompt() {
        return this.prompt;
    }
    /**
     * Gets the seed property value. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
     * @return a Integer
     */
    @jakarta.annotation.Nullable
    public Integer getSeed() {
        return this.seed;
    }
    /**
     * Gets the stop property value. Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
     * @return a CreateCompletionRequestStop
     */
    @jakarta.annotation.Nullable
    public CreateCompletionRequestStop getStop() {
        return this.stop;
    }
    /**
     * Gets the stream property value. Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
     * @return a Boolean
     */
    @jakarta.annotation.Nullable
    public Boolean getStream() {
        return this.stream;
    }
    /**
     * Gets the suffix property value. The suffix that comes after a completion of inserted text.
     * @return a String
     */
    @jakarta.annotation.Nullable
    public String getSuffix() {
        return this.suffix;
    }
    /**
     * Gets the temperature property value. What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.We generally recommend altering this or `top_p` but not both.
     * @return a Double
     */
    @jakarta.annotation.Nullable
    public Double getTemperature() {
        return this.temperature;
    }
    /**
     * Gets the top_p property value. An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.We generally recommend altering this or `temperature` but not both.
     * @return a Double
     */
    @jakarta.annotation.Nullable
    public Double getTopP() {
        return this.topP;
    }
    /**
     * Gets the user property value. A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @return a String
     */
    @jakarta.annotation.Nullable
    public String getUser() {
        return this.user;
    }
    /**
     * Serializes information the current object
     * @param writer Serialization writer to use to serialize this model
     */
    public void serialize(@jakarta.annotation.Nonnull final SerializationWriter writer) {
        Objects.requireNonNull(writer);
        writer.writeIntegerValue("best_of", this.getBestOf());
        writer.writeBooleanValue("echo", this.getEcho());
        writer.writeDoubleValue("frequency_penalty", this.getFrequencyPenalty());
        writer.writeObjectValue("logit_bias", this.getLogitBias());
        writer.writeIntegerValue("logprobs", this.getLogprobs());
        writer.writeIntegerValue("max_tokens", this.getMaxTokens());
        writer.writeObjectValue("model", this.getModel());
        writer.writeIntegerValue("n", this.getN());
        writer.writeDoubleValue("presence_penalty", this.getPresencePenalty());
        writer.writeObjectValue("prompt", this.getPrompt());
        writer.writeIntegerValue("seed", this.getSeed());
        writer.writeObjectValue("stop", this.getStop());
        writer.writeBooleanValue("stream", this.getStream());
        writer.writeStringValue("suffix", this.getSuffix());
        writer.writeDoubleValue("temperature", this.getTemperature());
        writer.writeDoubleValue("top_p", this.getTopP());
        writer.writeStringValue("user", this.getUser());
        writer.writeAdditionalData(this.getAdditionalData());
    }
    /**
     * Sets the AdditionalData property value. Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     * @param value Value to set for the AdditionalData property.
     */
    public void setAdditionalData(@jakarta.annotation.Nullable final Map<String, Object> value) {
        this.additionalData = value;
    }
    /**
     * Sets the best_of property value. Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return  `best_of` must be greater than `n`.**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
     * @param value Value to set for the best_of property.
     */
    public void setBestOf(@jakarta.annotation.Nullable final Integer value) {
        this.bestOf = value;
    }
    /**
     * Sets the echo property value. Echo back the prompt in addition to the completion
     * @param value Value to set for the echo property.
     */
    public void setEcho(@jakarta.annotation.Nullable final Boolean value) {
        this.echo = value;
    }
    /**
     * Sets the frequency_penalty property value. Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
     * @param value Value to set for the frequency_penalty property.
     */
    public void setFrequencyPenalty(@jakarta.annotation.Nullable final Double value) {
        this.frequencyPenalty = value;
    }
    /**
     * Sets the logit_bias property value. Modify the likelihood of specified tokens appearing in the completion.Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
     * @param value Value to set for the logit_bias property.
     */
    public void setLogitBias(@jakarta.annotation.Nullable final CreateCompletionRequestLogitBias value) {
        this.logitBias = value;
    }
    /**
     * Sets the logprobs property value. Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.The maximum value for `logprobs` is 5.
     * @param value Value to set for the logprobs property.
     */
    public void setLogprobs(@jakarta.annotation.Nullable final Integer value) {
        this.logprobs = value;
    }
    /**
     * Sets the max_tokens property value. The maximum number of [tokens](/tokenizer) that can be generated in the completion.The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
     * @param value Value to set for the max_tokens property.
     */
    public void setMaxTokens(@jakarta.annotation.Nullable final Integer value) {
        this.maxTokens = value;
    }
    /**
     * Sets the model property value. ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
     * @param value Value to set for the model property.
     */
    public void setModel(@jakarta.annotation.Nullable final CreateCompletionRequestModel value) {
        this.model = value;
    }
    /**
     * Sets the n property value. How many completions to generate for each prompt.**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
     * @param value Value to set for the n property.
     */
    public void setN(@jakarta.annotation.Nullable final Integer value) {
        this.n = value;
    }
    /**
     * Sets the presence_penalty property value. Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
     * @param value Value to set for the presence_penalty property.
     */
    public void setPresencePenalty(@jakarta.annotation.Nullable final Double value) {
        this.presencePenalty = value;
    }
    /**
     * Sets the prompt property value. The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
     * @param value Value to set for the prompt property.
     */
    public void setPrompt(@jakarta.annotation.Nullable final CreateCompletionRequestPrompt value) {
        this.prompt = value;
    }
    /**
     * Sets the seed property value. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
     * @param value Value to set for the seed property.
     */
    public void setSeed(@jakarta.annotation.Nullable final Integer value) {
        this.seed = value;
    }
    /**
     * Sets the stop property value. Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
     * @param value Value to set for the stop property.
     */
    public void setStop(@jakarta.annotation.Nullable final CreateCompletionRequestStop value) {
        this.stop = value;
    }
    /**
     * Sets the stream property value. Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
     * @param value Value to set for the stream property.
     */
    public void setStream(@jakarta.annotation.Nullable final Boolean value) {
        this.stream = value;
    }
    /**
     * Sets the suffix property value. The suffix that comes after a completion of inserted text.
     * @param value Value to set for the suffix property.
     */
    public void setSuffix(@jakarta.annotation.Nullable final String value) {
        this.suffix = value;
    }
    /**
     * Sets the temperature property value. What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.We generally recommend altering this or `top_p` but not both.
     * @param value Value to set for the temperature property.
     */
    public void setTemperature(@jakarta.annotation.Nullable final Double value) {
        this.temperature = value;
    }
    /**
     * Sets the top_p property value. An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.We generally recommend altering this or `temperature` but not both.
     * @param value Value to set for the top_p property.
     */
    public void setTopP(@jakarta.annotation.Nullable final Double value) {
        this.topP = value;
    }
    /**
     * Sets the user property value. A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @param value Value to set for the user property.
     */
    public void setUser(@jakarta.annotation.Nullable final String value) {
        this.user = value;
    }
    /**
     * Composed type wrapper for classes string
     */
    @jakarta.annotation.Generated("com.microsoft.kiota")
    public static class CreateCompletionRequestModel implements ComposedTypeWrapper, Parsable {
        /**
         * Composed type representation for type string
         */
        private String string;
        /**
         * Creates a new instance of the appropriate class based on discriminator value
         * @param parseNode The parse node to use to read the discriminator value and create the object
         * @return a CreateCompletionRequestModel
         */
        @jakarta.annotation.Nonnull
        public static CreateCompletionRequestModel createFromDiscriminatorValue(@jakarta.annotation.Nonnull final ParseNode parseNode) {
            Objects.requireNonNull(parseNode);
            final CreateCompletionRequestModel result = new CreateCompletionRequestModel();
            if (parseNode.getStringValue() != null) {
                result.setString(parseNode.getStringValue());
            }
            return result;
        }
        /**
         * The deserialization information for the current model
         * @return a Map<String, java.util.function.Consumer<ParseNode>>
         */
        @jakarta.annotation.Nonnull
        public Map<String, java.util.function.Consumer<ParseNode>> getFieldDeserializers() {
            return new HashMap<String, java.util.function.Consumer<ParseNode>>();
        }
        /**
         * Gets the string property value. Composed type representation for type string
         * @return a String
         */
        @jakarta.annotation.Nullable
        public String getString() {
            return this.string;
        }
        /**
         * Serializes information the current object
         * @param writer Serialization writer to use to serialize this model
         */
        public void serialize(@jakarta.annotation.Nonnull final SerializationWriter writer) {
            Objects.requireNonNull(writer);
            if (this.getString() != null) {
                writer.writeStringValue(null, this.getString());
            }
        }
        /**
         * Sets the string property value. Composed type representation for type string
         * @param value Value to set for the string property.
         */
        public void setString(@jakarta.annotation.Nullable final String value) {
            this.string = value;
        }
    }
    /**
     * Composed type wrapper for classes CreateCompletionRequest_promptMember1, integer, string
     */
    @jakarta.annotation.Generated("com.microsoft.kiota")
    public static class CreateCompletionRequestPrompt implements ComposedTypeWrapper, Parsable {
        /**
         * Composed type representation for type CreateCompletionRequest_promptMember1
         */
        private java.util.List<CreateCompletionRequestPromptMember1> createCompletionRequestPromptMember1;
        /**
         * Composed type representation for type integer
         */
        private Integer integer;
        /**
         * Composed type representation for type string
         */
        private String string;
        /**
         * Creates a new instance of the appropriate class based on discriminator value
         * @param parseNode The parse node to use to read the discriminator value and create the object
         * @return a CreateCompletionRequestPrompt
         */
        @jakarta.annotation.Nonnull
        public static CreateCompletionRequestPrompt createFromDiscriminatorValue(@jakarta.annotation.Nonnull final ParseNode parseNode) {
            Objects.requireNonNull(parseNode);
            final CreateCompletionRequestPrompt result = new CreateCompletionRequestPrompt();
            final ParseNode mappingValueNode = parseNode.getChildNode("");
            if (mappingValueNode != null) {
                final String mappingValue = mappingValueNode.getStringValue();
            }
            if (parseNode.getIntegerValue() != null) {
                result.setInteger(parseNode.getIntegerValue());
            } else if (parseNode.getStringValue() != null) {
                result.setString(parseNode.getStringValue());
            } else if (parseNode.getCollectionOfObjectValues(CreateCompletionRequestPromptMember1::createFromDiscriminatorValue) != null) {
                result.setCreateCompletionRequestPromptMember1(parseNode.getCollectionOfObjectValues(CreateCompletionRequestPromptMember1::createFromDiscriminatorValue));
            }
            return result;
        }
        /**
         * Gets the CreateCompletionRequest_promptMember1 property value. Composed type representation for type CreateCompletionRequest_promptMember1
         * @return a java.util.List<CreateCompletionRequestPromptMember1>
         */
        @jakarta.annotation.Nullable
        public java.util.List<CreateCompletionRequestPromptMember1> getCreateCompletionRequestPromptMember1() {
            return this.createCompletionRequestPromptMember1;
        }
        /**
         * The deserialization information for the current model
         * @return a Map<String, java.util.function.Consumer<ParseNode>>
         */
        @jakarta.annotation.Nonnull
        public Map<String, java.util.function.Consumer<ParseNode>> getFieldDeserializers() {
            return new HashMap<String, java.util.function.Consumer<ParseNode>>();
        }
        /**
         * Gets the integer property value. Composed type representation for type integer
         * @return a Integer
         */
        @jakarta.annotation.Nullable
        public Integer getInteger() {
            return this.integer;
        }
        /**
         * Gets the string property value. Composed type representation for type string
         * @return a String
         */
        @jakarta.annotation.Nullable
        public String getString() {
            return this.string;
        }
        /**
         * Serializes information the current object
         * @param writer Serialization writer to use to serialize this model
         */
        public void serialize(@jakarta.annotation.Nonnull final SerializationWriter writer) {
            Objects.requireNonNull(writer);
            if (this.getInteger() != null) {
                writer.writeIntegerValue(null, this.getInteger());
            } else if (this.getString() != null) {
                writer.writeStringValue(null, this.getString());
            } else if (this.getCreateCompletionRequestPromptMember1() != null) {
                writer.writeCollectionOfObjectValues(null, this.getCreateCompletionRequestPromptMember1());
            }
        }
        /**
         * Sets the CreateCompletionRequest_promptMember1 property value. Composed type representation for type CreateCompletionRequest_promptMember1
         * @param value Value to set for the CreateCompletionRequest_promptMember1 property.
         */
        public void setCreateCompletionRequestPromptMember1(@jakarta.annotation.Nullable final java.util.List<CreateCompletionRequestPromptMember1> value) {
            this.createCompletionRequestPromptMember1 = value;
        }
        /**
         * Sets the integer property value. Composed type representation for type integer
         * @param value Value to set for the integer property.
         */
        public void setInteger(@jakarta.annotation.Nullable final Integer value) {
            this.integer = value;
        }
        /**
         * Sets the string property value. Composed type representation for type string
         * @param value Value to set for the string property.
         */
        public void setString(@jakarta.annotation.Nullable final String value) {
            this.string = value;
        }
    }
    /**
     * Composed type wrapper for classes string
     */
    @jakarta.annotation.Generated("com.microsoft.kiota")
    public static class CreateCompletionRequestStop implements ComposedTypeWrapper, Parsable {
        /**
         * Composed type representation for type string
         */
        private String string;
        /**
         * Creates a new instance of the appropriate class based on discriminator value
         * @param parseNode The parse node to use to read the discriminator value and create the object
         * @return a CreateCompletionRequestStop
         */
        @jakarta.annotation.Nonnull
        public static CreateCompletionRequestStop createFromDiscriminatorValue(@jakarta.annotation.Nonnull final ParseNode parseNode) {
            Objects.requireNonNull(parseNode);
            final CreateCompletionRequestStop result = new CreateCompletionRequestStop();
            final ParseNode mappingValueNode = parseNode.getChildNode("");
            if (mappingValueNode != null) {
                final String mappingValue = mappingValueNode.getStringValue();
            }
            if (parseNode.getStringValue() != null) {
                result.setString(parseNode.getStringValue());
            }
            return result;
        }
        /**
         * The deserialization information for the current model
         * @return a Map<String, java.util.function.Consumer<ParseNode>>
         */
        @jakarta.annotation.Nonnull
        public Map<String, java.util.function.Consumer<ParseNode>> getFieldDeserializers() {
            return new HashMap<String, java.util.function.Consumer<ParseNode>>();
        }
        /**
         * Gets the string property value. Composed type representation for type string
         * @return a String
         */
        @jakarta.annotation.Nullable
        public String getString() {
            return this.string;
        }
        /**
         * Serializes information the current object
         * @param writer Serialization writer to use to serialize this model
         */
        public void serialize(@jakarta.annotation.Nonnull final SerializationWriter writer) {
            Objects.requireNonNull(writer);
            if (this.getString() != null) {
                writer.writeStringValue(null, this.getString());
            }
        }
        /**
         * Sets the string property value. Composed type representation for type string
         * @param value Value to set for the string property.
         */
        public void setString(@jakarta.annotation.Nullable final String value) {
            this.string = value;
        }
    }
}
